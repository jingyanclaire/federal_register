import re
import glob
import pandas as pd
import os

#find all of section first page headers 
def findSectionHeaders(index, file):
    sectionFound=False
    section="Notices"
    #patterns for each section's first page
    RRHeader=easierRegEx("Rules and Regulations")
    PRHeader=easierRegEx("Proposed Rules")
    noticeHeader= easierRegEx("Notices")
    #search first 10 lines within the index of where section header found
    for i in range(10):
        if not (sectionFound):
            line=file[index-i]
            #Find which section it most likely is
            RRHeadermatch=re.search(RRHeader, line, re.IGNORECASE)
            PRHeaderMatch=re.search(PRHeader, line, re.IGNORECASE)
            noticeHeaderMatch=re.search(noticeHeader, line, re.IGNORECASE)
            #store into right section and return back to loop
            if(RRHeadermatch):
                sectionFound=True
                section= 'Rules and Regulations'
            elif (PRHeaderMatch):
                sectionFound=True
                section= "Proposed Rules"
            elif(noticeHeaderMatch):
                sectionFound=True
                section="Notices"
            else:
                section="NOPE"
    return section

#find every section within a certain file 
def additionalSections(file_path, sectionDict):
    #initialize boolean variables for each section
    randRFound=False
    prFound=False
    noticeFound=False
    #patterns for each sections's regular page header
    randRPattern = easierRegEx("Federal Register")+"(.+?)"+r"[VY]\s*o\s*[li]\s*"+"(.*?)"+easierRegEx("No")+"(.+?)"+easierRegEx("Rules and Regulations")
    prPattern=easierRegEx("Federal Register")+"(.+?)"+r"[VY]\s*o\s*[li]\s*"+"(.*?)"+easierRegEx("No")+"(.+?)"+easierRegEx("Proposed Rules")
    noticePattern=easierRegEx("Federal Register")+"(.+?)"+r"[VY]\s*o\s*[li]\s*"+"(.*?)"+easierRegEx("No")+"(.+?)"+easierRegEx("Notices")
    sectionStart=r"T\s{0,3}h\s{0,3}i\s{0,3}s\s{0,3}[.,\s]*\s{0,3}s\s{0,3}e\s{0,3}c\s{0,3}t\s{0,3}i\s{0,3}o\s{0,3}n\s{0,3}[.,\s]*\s{0,3}o\s{0,3}f\s{0,3}[.,\s]*\s{0,3}t\s{0,3}h\s{0,3}e\s{0,3}[.,\s]*\s{0,3}F\s{0,3}E\s{0,3}D\s{0,3}E\s{0,3}R\s{0,3}A\s{0,3}L\s{0,3}[.,\s]*\s{0,3}R\s{0,3}E\s{0,3}G\s{0,3}[IT]\s{0,3}S\s{0,3}T\s{0,3}E\s{0,3}R\s{0,3}[.,\s]*"
    #pattern for reader aids
    readerAids=easierRegEx("ReaderAidsFederalRegister") 
    presidentialDocuments=easierRegEx("PresidentialDocuments")
    #read text file and read line by line 
    with open(file_path, 'r', encoding='utf-8') as file:
        linesList=file.readlines()
        for index,line in enumerate(linesList):
            section=""
            #find if there is a match for the pattern within the line
            RRmatches=re.findall(randRPattern, line, re.IGNORECASE)
            prMatches=re.findall(prPattern, line, re.IGNORECASE)
            noticeMatches=re.findall(noticePattern, line, re.IGNORECASE)
            readerMatches=re.findall(readerAids, line, re.IGNORECASE)
            prezMatches=re.search(presidentialDocuments, line, re.IGNORECASE)
            sectionHeaderMatch=re.search(sectionStart, line, re.IGNORECASE)
            #if there is a reader match, exit loop
            #if there is a match for one of the sections, store into that section's value within the dictionary
            if readerMatches or prezMatches:
                noticeFound=False
                prFound=False
                randRFound=False  
            #if it says "this section of the federal register" (used for first page of each section)
            elif(sectionHeaderMatch):
                #find which section it is referring to
                section=findSectionHeaders(index,linesList)
                #store into right section
                if (section!="NOPE"):
                    if(section=="Rules and Regulations"):
                        randRFound=True
                        prFound=False
                        noticeFound=False    
                        sectionDict["Rules and Regulations"]=sectionDict["Rules and Regulations"]+line
                    elif (section=="Proposed Rules"):
                        prFound=True
                        randRFound=False
                        noticeFound=False
                        sectionDict["Proposed Rules"]=sectionDict["Proposed Rules"]+line
                    else:
                        noticeFound=True
                        prFound=False
                        randRFound=False
                        sectionDict["Notices"]=sectionDict["Notices"]+line
            #Store into Rules and Regulations
            elif (len(RRmatches)>0 or (section=="Rules and Regulations")):
                randRFound=True
                prFound=False
                noticeFound=False
                sectionDict['Rules and Regulations']=sectionDict['Rules and Regulations']+line
            #Store into Proposed Rules
            elif ((len(prMatches)>0)or(section=="Proposed Rules")):
                prFound=True
                randRFound=False
                noticeFound=False
                sectionDict['Proposed Rules']=sectionDict['Proposed Rules']+line 
            #Store into Notices
            elif (len(noticeMatches)>0 or (section=="Notices")):
                noticeFound=True
                prFound=False
                randRFound=False
                sectionDict['Notices']=sectionDict['Notices']+line
            elif randRFound:
                sectionDict['Rules and Regulations']=sectionDict['Rules and Regulations']+line
            elif noticeFound:
                sectionDict['Notices']=sectionDict['Notices']+line
            elif prFound:
                sectionDict['Proposed Rules']=sectionDict['Proposed Rules']+line         


#find each entry within every section of a file
def find_each_file(sectionDict, date):
    #intialize list to store lists for every entry 
    fileList=[]
    #regex pattern for FR Doc. followed by four digits
    pattern = r"([FP]\s*R\s*D{1,2}\s*o{1,2}\s*c{1,2}\s*.+ f{1,2}\s*((i{1,2}\s*[f,l]{1,2}\s*)|(U\s*))e{1,2}\s*d{1,2}\s*.+[apfu].*[mn])"
    #for every section, and related text found in the dictionary
    for key, value in sectionDict.items():
        last=0
        #split every line and store into list
        lines_list = value.split("\n")
        findLast=True
        for j in range(len(lines_list)):
            if findLast:
                match=re.search(pattern, lines_list[len(lines_list)-1-j], re.IGNORECASE)
                if match:
                    last=len(lines_list)-j
                    findLast=False
        i=0
        while i<(len(lines_list)-1):
            line=lines_list[i]
            i=i+1
            #find if line contains FR Doc pattern
            match=re.search(pattern, line, re.IGNORECASE)
            #if it contains FR Doc pattern
            if match:
                #add the FR Doc Number as the number of the last entry as an indentifier  
                fileList[-1][0]=match.group(0)
                fileList[-1][1]=fileList[-1][1]+"\n"+line+"\n"+lines_list[i]
                #append a new entry 
                fileList.append(['',"", "",date])                            
            #if not the first entry in the list
            elif (len(fileList)>0) and (i<last):
                #if not the first line to be added as the text of the entry
                if fileList[-1][1]!= '':
                    #append line to the end of the entry with a new line character
                    fileList[-1][1]=fileList[-1][1]+"\n"+line
                    #append key of the entry
                    fileList[-1][2]=key
                else:
                    fileList[-1][1]=fileList[-1][1]+line
            #if first entry being analyzed, put placeholder for FR Doc number and append info
            elif (len(fileList)==0):
                fileList.append(["First Entry", line, key, date])
    return fileList          

#Find numbers at the beginning of CFR statements
def findNumber(file):
    #CFR Part ## pattern
    CFR=r"(\s*C\s{0,3}F\s{0,3}R\s{0,3}[.,\s]*\s{0,3}P\s{0,3}a\s{0,3}r\s{0,3}t\s{0,3}(s)?\s*\d{1,5})"
    #MakeSure its the right number
    dontRead=easierRegEx(r"List of subjects in")
    #Generate list of lines from text
    linesList=file[1].split("\n")
    #ensure pattern gets number before CFR
    pattern=r"^(.*?)"+CFR
    #intialize number
    number="0"
    #fot every line in the list of lines
    for index, line in enumerate(linesList):
        #go through first 15 lines of the file
        if index<15:
            #search for both
            match=re.search(pattern, line, re.IGNORECASE)
            dontReadMatch=re.search(dontRead, line, re.IGNORECASE)
            #if match found on the line
            if (match and not dontReadMatch):
                #get number
                number=match.group(1)
                number=number.strip()
                #return 0 if number too big
                if (len(number)>4):
                    number="0"
    return number

#check if number from the last file entry is the number before CFR for current file        
def CFRDetection(lines_list, number,ind, depAg, fileList):
    #pattern for what CFR not to read
    dontRead=easierRegEx("List of subjects in")
    #make sure number only has digits
    cleaned_text = re.sub(r'\D', '', number)
    #make number into a raw string
    raw_s = r'{}'.format(number)
    #pattern for number CFR Part ## 
    pattern=raw_s+r"(\s*C\s{0,3}F\s{0,3}R\s{0,3}[.,\s]*\s{0,3}P\s{0,3}a\s{0,3}r\s{0,3}t\s{0,3}(s)?\s*\d{1,5})"
    #initialize variables for whether the dep/agency has been found as well as the line counter
    Found=False
    #for every line in the file
    for index, line in enumerate(lines_list):
            #search only the first 20 lines
            if index <= 20:
            #as long a match hasn't been found yet, keep searching
                if not Found:
                    #use regEx to search within the line
                    match=re.search(pattern, line, re.IGNORECASE)
                    dontReadMatch=re.search(dontRead, line, re.IGNORECASE)
                    #if found, stop loop and store as the dep/agency for the entry
                    if (match and not dontReadMatch):
                        Found=True
                        fileList[ind].append(fileList[ind-1][depAg])  
    return Found  
                  
def findPreviousBillingCode(file):
    pattern=r"([BS8]\s{0,3}i\s{0,3}l\s{0,3}((l\s{0,3}i)|(U))\s{0,3}n\s{0,3}g\s{0,3}[.,\s]*\s{0,3}C\s{0,3}o\s{0,3}d\s{0,3}e\s{0,3})+((\d{1,4}\s{0,3}){1,4})"
    #Generate list of lines from text
    linesList=file[1].split("\n")
    #initialize billing code    
    billingCode=""
    #for every line in the list of lines
    for index, line in enumerate(linesList):
        #search for both
        match=re.search(pattern, line, re.IGNORECASE)
        #if match found on the line
        if (match):
            #get billing code
            number=(match.group(5)).replace(" ", "")
            number=easierRegEx(number)
            billingCode=r"([BS8]\s{0,3}i\s{0,3}l\s{0,3}((l\s{0,3}i)|(U))\s{0,3}n\s{0,3}g\s{0,3}[.,\s]*\s{0,3}C\s{0,3}o\s{0,3}d\s{0,3}e\s{0,3})"+number
    return billingCode

def billingCodeDetection(linesList, previousCode,fileIndex, dep_ag, fileList):
    pattern=(previousCode)
    found=False
    for index, line in enumerate(linesList):
        if ((len(linesList)-15)<index):
            match=re.search(pattern, line, re.IGNORECASE)
            if match:
                found=True
                print(fileIndex)
                fileList[fileIndex].append(fileList[fileIndex-1][dep_ag])
    return found
            
    
        
#find either department or agency being searched for and store into dataframe     
def find_dep_agency(file, lines_list, names_list, dep_ag, fileList, fileIndex):
    #initialize variables for whether the dep/agency has been found as well as the line counter
    Found=False
    #for every line and index within the lines list
    for index, line in enumerate(lines_list):
        #search only the first 20 lines
        if index <= 20:
            #for every name of dep/agency within the csv 
            for name in names_list:
                #create a easier to find regex statement
                regExDep=easierRegEx(name)
                #as long a match hasn't been found yet, keep searching
                if not Found:
                    #use regEx to search within the line
                    match=re.search(regExDep, line, re.IGNORECASE)
                    #if found, stop loop and store as the dep/agency for the entry
                    if match:
                        Found=True
                        if (match.group().isupper()):
                            file.append(name.upper())
                        else:
                            file.append(name)
                    #if not found
                    else:
                        #if not on the last line of the entry
                        if (index+1)<(len(lines_list)-1):
                            #combine former line and line after into a new line
                            newLine=line+lines_list[index+1]
                            #use regEx to search within the line
                            newMatch=re.search(regExDep, newLine, re.IGNORECASE)
                            #if found, stop loop and store as the dep/agency for the entry
                            if newMatch:
                                Found=True
                                if (newMatch.group().isupper()):
                                    file.append(name.upper())
                                else:
                                        file.append(name)
    #If either department of agency is not found
    if not Found:
        if ((fileList[fileIndex][2]=="Rules and Regulations")or(fileList[fileIndex][2]=="Proposed Rules")):
            #find the CFR number for last file and return 
            number=findNumber(fileList[fileIndex-1])
            #If the number is not 0, try to find CFR
            if (number!="0"):
                Found=CFRDetection(lines_list, number,fileIndex, dep_ag, fileList)
        else:
            previousCode=findPreviousBillingCode(fileList[fileIndex-1])
            if (previousCode!=""):
                Found=billingCodeDetection(lines_list, previousCode,fileIndex, dep_ag, fileList)            

    #if still not found, dep/ag was not found
    if not Found:
        file.append("Not Found")
        
#read either department or agency names from a given csv
def read_agency_names_from_csv(file_path,name):
    df = pd.read_csv(file_path)
    return df[name].tolist() 

#store department and agency names into pandas dataframes and start search for both
def find_department(fileList):
    #read each name in department csv to a list
    department_names_list = read_agency_names_from_csv("department_names_only.csv", 'department.name')
    
    #read each name in the agency csv to a list
    agency_names_list = read_agency_names_from_csv("agency_names_only.csv", 'agency.name')
    
    #for every entry found in the entry list
    for index,file in enumerate(fileList):
        #split after each line and store each line to a list
        text=file[1]
        lines_list = text.split("\n")
        
        #find department for the entry
        find_dep_agency(file, lines_list, department_names_list, 4,fileList, index)
        
        #find agency for the entry
        find_dep_agency(file, lines_list, agency_names_list, 5, fileList, index)

        
            
#take every word in the string being searched for, add a [.,\s]* after
#after every letter add a \s{0,3}
def easierRegEx(string):
    LetterSeparator=''
    regexDep=""
    #for each letter in the string, add a \s{0,3}
    #allows for zero-three spaces between the letters to account for encoding errors with spacing
    for letter in string:
        if(letter!=''):
            LetterSeparator=LetterSeparator+letter+'\s{0,3}'
    #for each word in the string, add a [.,\s]*
    #allows for zero or more occurances of a white space, period or comma between words to account for 90s agency formatting
    departmentWords = LetterSeparator.split()
    for word in departmentWords:
           regexDep=regexDep+word+'[.,\s]*'
    return regexDep

 

#avoid false positive departmental detections when no department 
def cleanUpList(fileList):
    for file in fileList:
        if file[5].isupper():
            file[4]='Not Found'
    fileList.pop()


#store collected data into dataframes
def makeDataframe(fileList):
    # Column names for the DataFrame
    columns = ['FR Doc. Number', 'Text', 'Section','Date','Department', 'Agency' , 'New', "new"]

    df = pd.DataFrame(fileList, columns=columns)
    #create data frame without text
    csvDf=df.drop('Text', axis=1)
    print(df)
    #find all emtpy files
    empty=csvDf.loc[(df['Department'] == "Not Found") & (df['Agency'] == "Not Found")]
    #output directory
    directory = './output'
    #fileName for both files
    filename = str(csvDf.iloc[0]['Date'])+'.csv'
    textFileName=str(csvDf.iloc[0]['Date'])+'text'+'.csv'
    emptyFileName=(csvDf.iloc[0]['Date'])+'empty'+'.csv'
    #path to write output files
    file_path = os.path.join(directory, filename)
    file_pathTEXt=os.path.join(directory, textFileName)
    file_pathEmpty=os.path.join(directory, emptyFileName)
    #create folder if not present
    if not os.path.isdir(directory):
        os.mkdir(directory)
    #write dataframes to csv files
    csvDf.to_csv(file_path,index=True)
    df.to_csv(file_pathTEXt,index=True)
    empty.to_csv(file_pathEmpty, index=True)
    return df
        
def main():
    #folder containing text files that need analysis
    folder_path = r'C:\Users\vishp\Desktop\Python\FDR\Extracting_info\Dates/*.txt'
    #list containing every file path within the folder
    text_files = glob.glob(folder_path)
    #for every file in the folder contain the files that are being analyzed 
    for file_path in text_files:
        #remake the dictionary
        sectionDict={'Rules and Regulations':'', 'Proposed Rules':'', 'Notices':''}
        #find date using the text file's name
        date=os.path.basename(file_path).split('.txt')[0]
        #find sections
        additionalSections(file_path, sectionDict)
        # for key, value in sectionDict.items():
        #     with open(key+".txt", 'w', encoding='utf-8') as file:
        #         file.write(value)
        #find each entry
        fileList=find_each_file(sectionDict, date)
        #find department and/or agency
        find_department(fileList)
        #clean up list
        cleanUpList(fileList)
        #store entry data into a dataframe
        df=makeDataframe(fileList)

if __name__ == "__main__":
    main()
    
