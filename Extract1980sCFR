import re
import glob
import pandas as pd
import os
import concurrent.futures

#find all of section first page headers 
def findSectionHeaders(index, file):
    sectionFound=False
    section="Notices"
    #patterns for each section's first page
    RRHeader=easierRegEx("Rules and Regulations")
    PRHeader=easierRegEx("Proposed Rules")
    noticeHeader= easierRegEx("Notices")
              
    #search first 10 lines within the index of where section header found
    for i in range(10):
        if not (sectionFound):
            line=file[index-i]
            #Find which section it most likely is
            RRHeadermatch=re.search(RRHeader, line, re.IGNORECASE)
            PRHeaderMatch=re.search(PRHeader, line, re.IGNORECASE)
            noticeHeaderMatch=re.search(noticeHeader, line, re.IGNORECASE)
            #store into right section and return back to loop
            if(RRHeadermatch):
                sectionFound=True
                section= 'Rules and Regulations'
            elif (PRHeaderMatch):
                sectionFound=True
                section= "Proposed Rules"
            elif(noticeHeaderMatch):
                sectionFound=True
                section="Notices"
            else:
                section="NOPE"  
    for i in range(5):
       if not (sectionFound):
            line=file[index+i]
            #Find which section it most likely is
            RRHeadermatch=re.search(RRHeader, line, re.IGNORECASE)
            PRHeaderMatch=re.search(PRHeader, line, re.IGNORECASE)
            noticeHeaderMatch=re.search(noticeHeader, line, re.IGNORECASE)
            #store into right section and return back to loop
            if(RRHeadermatch):
                sectionFound=True
                section= 'Rules and Regulations'
            elif (PRHeaderMatch):
                sectionFound=True
                section= "Proposed Rules"
            elif(noticeHeaderMatch):
                sectionFound=True
                section="Notices"
            else:
                section="NOPE"
    return section

#find every section within a certain file 
def additionalSections(file_path, sectionDict):
    #initialize boolean variables for each section
    randRFound=False
    prFound=False
    noticeFound=False
    #patterns for each sections's regular page header
    randRPattern = easierRegEx("Federal Register")+"(.+?)"+r"[VY]\s*o\s*[li]\s*"+"(.*?)"+easierRegEx("No")+"(.+?)"+easierRegEx("Rules and Regulations")
    prPattern=easierRegEx("Federal Register")+"(.+?)"+r"[VY]\s*o\s*[li]\s*"+"(.*?)"+easierRegEx("No")+r"(.+?)"+r"(P\s{0,3}r\s{0,3}o\s{0,3}[pn]\s{0,3}o\s{0,3}s\s{0,3}e\s{0,3}d\s{0,3}[.,\s]*((R\s{0,3}u\s{0,3}l\s{0,3}e\s{0,3}s\s{0,3})|((R\s{0,3}i\s{0,3}d\s{0,3}e\s{0,3}s\s{0,3})))[.,\s]*)"
    noticePattern=easierRegEx("Federal Register")+"(.+?)"+r"[VY]\s*o\s*[li]\s*"+"(.*?)"+easierRegEx("No")+"(.+?)"+easierRegEx("Notices")
    sectionStart=easierRegEx("this section of the federal register")
    #pattern for reader aids
    readerAids=easierRegEx("ReaderAidsFederalRegister") 
    presidentialDocuments=easierRegEx("PresidentialDocuments")
    #read text file and read line by line 
    with open(file_path, 'r', encoding='utf-8') as file:
        linesList=file.readlines()
        for index,line in enumerate(linesList):
            section=""
            #find if there is a match for the pattern within the line
            RRmatches=re.findall(randRPattern, line, re.IGNORECASE)
            prMatches=re.findall(prPattern, line, re.IGNORECASE)
            noticeMatches=re.findall(noticePattern, line, re.IGNORECASE)
            readerMatches=re.findall(readerAids, line, re.IGNORECASE)
            prezMatches=re.search(presidentialDocuments, line, re.IGNORECASE)
            sectionHeaderMatch=re.search(sectionStart, line, re.IGNORECASE)
            #if there is a reader match, exit loop
            #if there is a match for one of the sections, store into that section's value within the dictionary
            if readerMatches or prezMatches:
                noticeFound=False
                prFound=False
                randRFound=False  
            #if it says "this section of the federal register" (used for first page of each section)
            elif(sectionHeaderMatch):
                #find which section it is referring to
                section=findSectionHeaders(index,linesList)
                #store into right section
                if (section!="NOPE"):
                    if(section=="Rules and Regulations"):
                        randRFound=True
                        prFound=False
                        noticeFound=False    
                        sectionDict["Rules and Regulations"]=sectionDict["Rules and Regulations"]+line
                    elif (section=="Proposed Rules"):
                        prFound=True
                        randRFound=False
                        noticeFound=False
                        sectionDict["Proposed Rules"]=sectionDict["Proposed Rules"]+line
                    else:
                        noticeFound=True
                        prFound=False
                        randRFound=False
                        sectionDict["Notices"]=sectionDict["Notices"]+line
            #Store into Rules and Regulations
            elif (len(RRmatches)>0 or (section=="Rules and Regulations")):
                randRFound=True
                prFound=False
                noticeFound=False
                sectionDict['Rules and Regulations']=sectionDict['Rules and Regulations']+line
            #Store into Proposed Rules
            elif ((len(prMatches)>0)or(section=="Proposed Rules")):
                prFound=True
                randRFound=False
                noticeFound=False
                sectionDict['Proposed Rules']=sectionDict['Proposed Rules']+line 
            #Store into Notices
            elif (len(noticeMatches)>0 or (section=="Notices")):
                noticeFound=True
                prFound=False
                randRFound=False
                sectionDict['Notices']=sectionDict['Notices']+line
            elif randRFound:
                sectionDict['Rules and Regulations']=sectionDict['Rules and Regulations']+line
            elif noticeFound:
                sectionDict['Notices']=sectionDict['Notices']+line
            elif prFound:
                sectionDict['Proposed Rules']=sectionDict['Proposed Rules']+line         


#find each entry within every section of a file
def find_each_file(sectionDict, date):
    #intialize list to store lists for every entry 
    fileList=[]
    #regex pattern for FR Doc. followed by four digits
    pattern = r"([FP]\s*R\s*D{1,2}\s*o{1,2}\s*c{1,2}\s*.+ f{1,2}\s*((i{1,2}\s*[f,l]{1,2}\s*)|(U\s*))e{1,2}\s*d{1,2}\s*.+[apfu].*[mn])"
    #for every section, and related text found in the dictionary
    for key, value in sectionDict.items():
        last=0
        #split every line and store into list
        lines_list = value.split("\n")
        findLast=True
        for j in range(len(lines_list)):
            if findLast:
                match=re.search(pattern, lines_list[len(lines_list)-1-j], re.IGNORECASE)
                if match:
                    last=len(lines_list)-j
                    findLast=False
        i=0
        while i<(len(lines_list)-1):
            line=lines_list[i]
            i=i+1
            #find if line contains FR Doc pattern
            match=re.search(pattern, line, re.IGNORECASE)
            #if it contains FR Doc pattern
            if match:
                #add the FR Doc Number as the number of the last entry as an indentifier  
                fileList[-1][0]=match.group(1)
                fileList[-1][1]=fileList[-1][1]+"\n"+line+"\n"+lines_list[i]
                #append a new entry 
                fileList.append(['',"", "",date, "", ""])                            
            #if not the first entry in the list
            elif (len(fileList)>0) and (i<last):
                #if not the first line to be added as the text of the entry
                if fileList[-1][1]!= '':
                    #append line to the end of the entry with a new line character
                    fileList[-1][1]=fileList[-1][1]+"\n"+line
                    #append key of the entry
                    fileList[-1][2]=key
                else:
                    fileList[-1][1]=fileList[-1][1]+line
            #if first entry being analyzed, put placeholder for FR Doc number and append info
            elif (len(fileList)==0):
                fileList.append(["First Entry", line, key, date, "", ""])
    return fileList          
            
def findPreviousBillingCode(file):
    pattern=r"([BS8M]\s{0,3}(i|U)\s{0,3}l\s{0,3}((l\s{0,3}i)|(U))\s{0,3}n\s{0,3}g\s{0,3}[.,\s]*\s{0,3}C\s{0,3}(o|0)\s{0,3}(D|T|O)\s{0,3}e\s{0,3}).+((\d{1,4}\s{0,3}){1,4})"
    pattern2=r"((\d{1,4}\s{0,3}){1,4})"
    #Generate list of lines from text
    linesList=file[1].split("\n")
    #initialize billing code    
    billingCode=""
    # define the mapping table
    mapping_table = str.maketrans({'0': '[0o]', 'O': '[0o]', 's':'[5s]', '5':'[5s]', })
    
    #for every line in the list of lines
    for index, line in enumerate(linesList):
        #search for both
        match=re.search(pattern, line, re.IGNORECASE)
        #if match found on the line
        if (match):
            match2=re.search(pattern2, match.group(), re.IGNORECASE)
            if(match2):
                #get billing code
                number=(match2.group()).replace(" ", "")
                numberAlt=(str(int(number)+1))
                # use translate() method to replace characters
                numberAlt = numberAlt.translate(mapping_table)
                number=number.translate(mapping_table)
                number=easierRegEx(number)
                numberAlt=easierRegEx(numberAlt)
                billingCode=r"([BS8M]\s{0,3}(i|U)\s{0,3}l\s{0,3}((l\s{0,3}i)|(U))\s{0,3}n\s{0,3}g\s{0,3}[.,\s]*\s{0,3}C\s{0,3}[0o]\s{0,3}(D|T|O)\s{0,3}e\s{0,3}).+("+number+'|'+numberAlt+')'
    return billingCode

def billingCodeDetection(linesList, previousCode,fileIndex, dep_ag, fileList):
    pattern=(previousCode)
    found=False
    for index, line in enumerate(linesList):
        if ((len(linesList)-15)<index):
            match=re.search(pattern, line, re.IGNORECASE)
            if match:
                found=True
                if (fileIndex)>1:
                    fileList[fileIndex][dep_ag]=(fileList[fileIndex-1][dep_ag])
    return found
            
#find either department or agency being searched for and store into dataframe     
def find_dep_agency(file, lines_list, names_list, dep_ag, fileList, fileIndex):
    #initialize variables for whether the dep/agency has been found as well as the line counter
    Found=False
    lineLimit=20
    #for every line and index within the lines list
    for index, line in enumerate(lines_list):
        #search only the first 20 lines
        if index <= lineLimit:
            if len(line)<3:
                lineLimit=lineLimit+1
            #for every name of dep/agency within the csv 
            for name in names_list:
                #create a easier to find regex statement
                name=name[:43]
                regExDep=easierRegEx(name)
                #as long a match hasn't been found yet, keep searching
                if not Found:
                    #use regEx to search within the line
                    match=re.search(regExDep, line, re.IGNORECASE)
                    #if found, stop loop and store as the dep/agency for the entry
                    if match:
                        Found=True
                        if (match.group().isupper()):
                            file[dep_ag]=(name.upper())
                        else:
                            file[dep_ag]=name
                    #if not found
                    else:
                        #if not on the last line of the entry
                        if (index+1)<(len(lines_list)-1):
                            #combine former line and line after into a new line
                            newLine=line+lines_list[index+1]
                            #use regEx to search within the line
                            newMatch=re.search(regExDep, newLine, re.IGNORECASE)
                            #if found, stop loop and store as the dep/agency for the entry
                            if newMatch:
                                Found=True
                                if (newMatch.group().isupper()):
                                    file[dep_ag]=(name.upper())
                                else:
                                    file[dep_ag]=name
    for i in range(1,3):        
        if not Found:
            if (fileIndex>i):
                previousCode=findPreviousBillingCode(fileList[fileIndex-i])
                if (previousCode!=""):
                    Found=billingCodeDetection(lines_list, previousCode,fileIndex, dep_ag, fileList)            
    #if still not found, dep/ag was not found
    if not Found:
        file[dep_ag]="Not Found"
        
#read either department or agency names from a given csv
def read_agency_names_from_csv(file_path,name):
    df = pd.read_csv(file_path)
    return df[name].tolist() 

#store department and agency names into pandas dataframes and start search for both
def find_department(fileList):
    #read each name in department csv to a list
    department_names_list = read_agency_names_from_csv("department_names_only.csv", 'department.name')
    
    #read each name in the agency csv to a list
    agency_names_list = read_agency_names_from_csv("agency_names_only.csv", 'agency.name')
    
    #for every entry found in the entry list
    for index,file in enumerate(fileList):
        #split after each line and store each line to a list
        text=file[1]
        lines_list = text.split("\n")
        
        #find department for the entry
        find_dep_agency(file, lines_list, department_names_list, 4,fileList, index)
        
        #find agency for the entry
        find_dep_agency(file, lines_list, agency_names_list, 5, fileList, index)

        
            
#take every word in the string being searched for, add a [.,\s]* after
#after every letter add a \s{0,3}
def easierRegEx(string):
    LetterSeparator=''
    regexDep=""
    #for each letter in the string, add a \s{0,3}
    #allows for zero-three spaces between the letters to account for encoding errors with spacing
    for letter in string:
        if(letter!=''):
            LetterSeparator=LetterSeparator+letter+'\s{0,3}'
    #for each word in the string, add a [.,\s]*
    #allows for zero or more occurances of a white space, period or comma between words to account for 90s agency formatting
    departmentWords = LetterSeparator.split()
    for word in departmentWords:
           regexDep=regexDep+word+'[.,\s\\n\d]*'
    return regexDep

 

#avoid false positive departmental detections when no department 
def cleanUpList(fileList):
    for file in fileList:
        if file[5].isupper():
            file[4]='Not Found'
    fileList.pop()


#store collected data into dataframes
def makeDataframe(fileList):
    # Column names for the DataFrame
    columns = ['FR Doc. Number', 'Text', 'Section','Date','Department', 'Agency']

    df = pd.DataFrame(fileList, columns=columns)
    #create data frame without text
    csvDf=df.drop('Text', axis=1)
    print(df)
    #find all emtpy files
    empty=csvDf.loc[(df['Department'] == "Not Found") & (df['Agency'] == "Not Found")]
    #output directory
    directory = './output'
    #fileName for both files
    filename = str(csvDf.iloc[0]['Date'])+'.csv'
    textFileName=str(csvDf.iloc[0]['Date'])+'text'+'.csv'
    emptyFileName=(csvDf.iloc[0]['Date'])+'empty'+'.csv'
    #path to write output files
    file_path = os.path.join(directory, filename)
    file_pathTEXt=os.path.join(directory, textFileName)
    file_pathEmpty=os.path.join(directory, emptyFileName)
    #create folder if not present
    if not os.path.isdir(directory):
        os.mkdir(directory)
    #write dataframes to csv files
    csvDf.to_csv(file_path,index=True)
    df.to_csv(file_pathTEXt,index=True)
    empty.to_csv(file_pathEmpty, index=True)
    return df
        

def analyze_file(file_path):
    #remake the dictionary
    sectionDict={'Rules and Regulations':'', 'Proposed Rules':'', 'Notices':''}
    #find date using the text file's name
    date=os.path.basename(file_path).split('.txt')[0]
    #find sections
    additionalSections(file_path, sectionDict)
    # for key, value in sectionDict.items():
    #     with open(key+".txt", 'w', encoding='utf-8') as file:
    #         file.write(value)
    #find each entry
    fileList=find_each_file(sectionDict, date)
    #find department and/or agency
    find_department(fileList)
    #clean up list
    cleanUpList(fileList)
    #store entry data into a dataframe
    df=makeDataframe(fileList)
    
def main():
     #folder containing text files that need analysis
    folder_path = r'C:\Users\vishp\Desktop\Python\FDR\Extracting_info\Dates/*.txt'
    #list containing every file path within the folder
    text_files = glob.glob(folder_path)
    for file_path in text_files:
        analyze_file(file_path)


if __name__ == "__main__":
    main()
    
